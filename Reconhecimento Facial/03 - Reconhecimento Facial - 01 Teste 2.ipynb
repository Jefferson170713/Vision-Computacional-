{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biblliotecas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função para pegar as imagens.\n",
    "    - Gerando um 2 arrays\n",
    "        - 1. Array de id.\n",
    "        - 2. Uma matriz de pixels feita em np.array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconhecedor_testes():\n",
    "    \n",
    "    paths = [os.path.join('./New_DB/yalefaces/test/', p) for p in os.listdir('./New_DB/yalefaces/test/')]\n",
    "    faces =[]\n",
    "    ids = []\n",
    "    \n",
    "    for path in paths:\n",
    "        imagem = Image.open(path).convert('L')\n",
    "        image_np = np.array(imagem, 'uint8')\n",
    "        \n",
    "        id = int(os.path.split(path)[1].split('.')[0].replace('subject',''))\n",
    "        ids.append(id)\n",
    "        faces.append(image_np)\n",
    "    \n",
    "    return ids, faces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sabendo as quantidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "id, face = reconhecedor_testes()\n",
    "print(len(id))\n",
    "print(len(face))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para treinar e saber as Predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_previsao(faces_np):\n",
    "    \n",
    "    lbph_classifier_fotos = cv2.face.LBPHFaceRecognizer_create()#cv2.face.LBPHRecognizer_create() \n",
    "    lbph_classifier_fotos.read('./lbph_classifier.yml')\n",
    "    \n",
    "    previsoes = []\n",
    "    \n",
    "    for foto in faces_np:\n",
    "        predict = lbph_classifier_fotos.predict(foto)\n",
    "        previsoes.append(predict)\n",
    "        #preciso colocar uma função que pegue todos as imagens.\n",
    "    \n",
    "    return previsoes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para mostrar as fotos a partir de uma condição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_valores(ids, faces, predicoes):\n",
    "    contador = 0\n",
    "    for n, p in enumerate(faces):\n",
    "        i, j = predicoes[n]\n",
    "        if  (j > 30): #(ids[n] == i) and\n",
    "            print(f'{i} é face : {j}')\n",
    "            contador += 1\n",
    "            j = np.round(j, 2)\n",
    "            cv2.putText(p, 'Pred :' + str(i), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255,0))\n",
    "            cv2.putText(p, '% :' + str(j), (20,50) , cv2.FONT_HERSHEY_COMPLEX_SMALL, 1,(0,255,0))\n",
    "            cv2.imshow(\"\",p)\n",
    "            cv2.waitKey(0)\n",
    "                   \n",
    "    print(contador)\n",
    "            \n",
    "   \n",
    "    \n",
    "    #for n, p in enumerate(mostrar):\n",
    "       # print(f'{n+1} : {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 22.62525404335563), (1, 10.516486843653137), (4, 25.052986207462283), (5, 25.779173954992928), (3, 13.081488574279117), (9, 27.040500557165878), (9, 25.87783432751071), (4, 9.581683012434771), (5, 7.936066004950048), (5, 9.404416693842116), (6, 9.777298274982265), (14, 33.40866312083982), (7, 12.01175080395902), (9, 22.901499201898798), (8, 0.0), (4, 36.73312234938682), (7, 25.614281240814968), (9, 10.500599116253822), (4, 19.05638321614462), (10, 6.384336446373091), (11, 11.717132147231391), (11, 11.668634234948554), (12, 0.0), (12, 49.07870382470524), (13, 6.141108281668351), (13, 6.898611904827257), (14, 0.0), (14, 9.736137850357382), (7, 28.513286928130153), (15, 8.440935126341593)]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "predicts = mostrar_previsao(face)\n",
    "print(predicts)\n",
    "print(len(predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"\", face[0])\n",
    "cv2.waitKey(0)\n",
    "#mostrar_valores(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 é face : 33.40866312083982\n",
      "4 é face : 36.73312234938682\n",
      "12 é face : 49.07870382470524\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "mostrar_valores(id, face, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 22.62525404335563),\n",
       " (1, 10.516486843653137),\n",
       " (4, 25.052986207462283),\n",
       " (5, 25.779173954992928),\n",
       " (3, 13.081488574279117),\n",
       " (9, 27.040500557165878),\n",
       " (9, 25.87783432751071),\n",
       " (4, 9.581683012434771),\n",
       " (5, 7.936066004950048),\n",
       " (5, 9.404416693842116),\n",
       " (6, 9.777298274982265),\n",
       " (14, 33.40866312083982),\n",
       " (7, 12.01175080395902),\n",
       " (9, 22.901499201898798),\n",
       " (8, 0.0),\n",
       " (4, 36.73312234938682),\n",
       " (7, 25.614281240814968),\n",
       " (9, 10.500599116253822),\n",
       " (4, 19.05638321614462),\n",
       " (10, 6.384336446373091),\n",
       " (11, 11.717132147231391),\n",
       " (11, 11.668634234948554),\n",
       " (12, 0.0),\n",
       " (12, 49.07870382470524),\n",
       " (13, 6.141108281668351),\n",
       " (13, 6.898611904827257),\n",
       " (14, 0.0),\n",
       " (14, 9.736137850357382),\n",
       " (7, 28.513286928130153),\n",
       " (15, 8.440935126341593)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
